## TODO

1. Attention Is All You Need Textbook:
  - add **Positional Encoding** section.
  - add **Attention Mechanism** section.

2. RAG PyTorch from scratch:
  - follow the **Local Retrieval Augmented Generation (RAG) from Scratch (step by step tutorial)** Tutorial from Daniel Bourke.